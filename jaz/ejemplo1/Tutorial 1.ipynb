{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 1 smolagent\n",
    "https://huggingface.co/docs/smolagents/guided_tour?Pick+a+LLM=HF+Inference+API\n",
    "\n",
    "NOTA: Recomendable ejecutarlo en un entorno virtual de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smolagents smolagents[litellm] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\" \n",
    "# model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar la clave de hugging face desde el fichero .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Crear el modelo con LiteLLM (los modelos creado con HF Inference API parece ser que consumen más tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel\n",
    "\n",
    "model = LiteLLMModel(model_id='huggingface/'+model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = agent.prompt_templates\n",
    "agent.prompt_templates['system_prompt'] += \"\\nWhen you generate a final answer, you must stop immediately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent\n",
    "\n",
    "agent = CodeAgent(tools=[], model=model, add_base_tools=True)\n",
    "set_system_prompt(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.run(\n",
    "    \"Could you give me the 118th number in the Fibonacci sequence?\",\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado anterior algunas veces sale mal.\n",
    "\n",
    "UNA SOLUCION:\n",
    "\n",
    "Si se define la función de fibonacci como una tool y ya da el resultado correcto:\n",
    "\n",
    "NOTA: Cuando se usa @tool, para que no salga un error, dentro de def es obligatorio el bloque siguiente:\n",
    "\n",
    "    \"\"\"\n",
    "    Calcula el enésimo número de Fibonacci.\n",
    "\n",
    "    Args:\n",
    "        n: Posición del número de fibonacci a calcular.\n",
    "    \"\"\"\n",
    "\n",
    "En la documentación lo indican así:\n",
    "\n",
    "The function needs:\n",
    "\n",
    "A clear name.\n",
    "The name should be descriptive enough of what this tool does to help the LLM brain powering the agent. Since this tool returns the model with the most downloads for a task, let’s name it model_download_tool.\n",
    "Type hints on both inputs and output.\n",
    "\n",
    "A description, that includes an ‘Args:’ part where each argument is described (without a type indication this time, it will be pulled from the type hint). Same as for the tool name, this description is an instruction manual for the LLM powering you agent, so do not neglect it. All these elements will be automatically baked into the agent’s system prompt upon initialization: so strive to make them as clear as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "@tool\n",
    "def fibonacci(n: int) -> int:\n",
    "    \"\"\"\n",
    "    Calcula el enésimo número de Fibonacci.\n",
    "\n",
    "    Args:\n",
    "        n: Posición del número de fibonacci a calcular.\n",
    "    \"\"\"\n",
    "\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n - 1):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\n",
    "# Configurar el agente con la tool de Fibonacci que acabamos de definir\n",
    "agent = CodeAgent(tools=[fibonacci], model=model, add_base_tools=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Se puede apreciar que hay un error interno porque en el step 2 ya se detecta final_answer, pero sigue en ejecución consumiendo tokens hasta el límite de pasos establecido.\n",
    "\n",
    "El siguiente código modifica el system_prompt para corregir este error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = agent.prompt_templates\n",
    "agent.prompt_templates['system_prompt'] += \"\\nWhen you generate a final answer, you must stop immediately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la consulta al agente\n",
    "response = agent.run(\"What is the 118th Fibonacci number?\")\n",
    "\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otra forma de definir la tool pero usando una class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear la class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents.tools import Tool\n",
    "\n",
    "# Definir la clase Fibonacci heredando de Tool\n",
    "class FibonacciTool(Tool):\n",
    "    name = \"fibonacci\"  # Agregamos el atributo name\n",
    "    description = \"Calculates the nth Fibonacci number.\"\n",
    "    inputs = {\n",
    "        \"n\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The position in the Fibonacci sequence to calculate\"\n",
    "        }\n",
    "    }\n",
    "    output_type = \"integer\"  # Añadimos el tipo de salida\n",
    "     \n",
    "    def forward(self, n: int) -> int:\n",
    "        \"\"\"Calcula el enésimo número de Fibonacci.\"\"\"\n",
    "        a, b = 0, 1\n",
    "        for _ in range(n - 1):\n",
    "            a, b = b, a + b\n",
    "        return a\n",
    "\n",
    "# Crear una instancia de la herramienta\n",
    "fibonacci_tool = FibonacciTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools=[fibonacci_tool], model=model, add_base_tools=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Se puede apreciar que hay un error interno porque en el step 2 ya se detecta final_answer, pero sigue en ejecución consumiendo tokens hasta el límite de pasos establecido.\n",
    "\n",
    "En este caso, el siguiente código modifica el system_prompt pero no consigue corregir este error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_templates = agent.prompt_templates\n",
    "agent.prompt_templates['system_prompt'] += \"\\nWhen you generate a final answer, you must stop immediately.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la consulta al agente\n",
    "response = agent.run(\"What is the 118th Fibonacci number?\")\n",
    "\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting an agent run\n",
    "\n",
    "Here are a few useful attributes to inspect what happened after a run:\n",
    "\n",
    "agent.logs\n",
    "\n",
    "Stores the fine-grained logs of the agent. At every step of the agent’s run, everything gets stored in a dictionary that then is appended to agent.logs.\n",
    "\n",
    "Running agent.\n",
    "\n",
    "write_memory_to_messages() writes the agent’s memory as list of chat messages for the Model to view. This method goes over each step of the log and only stores what it’s interested in as a message: for instance, it will save the system prompt and task in separate messages, then for each step it will store the LLM output as a message, and the tool call output as another message. Use this if you want a higher-level view of what has happened - but not every log will be transcripted by this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# agent.logs    # deprecated, use agent.memory.steps\n",
    "\n",
    "pprint.pprint(agent.memory.steps)print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
