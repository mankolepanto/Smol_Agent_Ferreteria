{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial smolagent\n",
    "https://huggingface.co/docs/smolagents/guided_tour?Pick+a+LLM=HF+Inference+API\n",
    "\n",
    "NOTA: Recomendable ejecutarlo en un entorno virtual de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smolagents python-dotenv \n",
    "#transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno del archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Acceder a la clave privada\n",
    "hf_key = os.getenv(\"HF_TOKEN\")\n",
    "#!huggingface-cli login --token $hf_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.3-70B-Instruct\" \n",
    "# model_id = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
    "# model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1. Usando HF Inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "\n",
    "model = HfApiModel(model_id=model_id, token=hf_key) # You can choose to not pass any model_id to HfApiModel to use a default free model\n",
    "# you can also specify a particular provider e.g. provider=\"together\" or provider=\"sambanova\"\n",
    "agent = CodeAgent(tools=[], model=model, add_base_tools=True)\n",
    "\n",
    "agent.run(\n",
    "    \"Could you give me the 118th number in the Fibonacci sequence?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado a veces sale bien y otras no.\n",
    "\n",
    "En el siguiente ejemplo, se define la función de fibonacci como una tool y entonces ya da el resultado correcto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "@tool\n",
    "def fibonacci(n: int) -> int:\n",
    "    \"\"\"\n",
    "    Calcula el enésimo número de Fibonacci.\n",
    "\n",
    "    Args:\n",
    "        n: Posición del número de fibonacci a calcular.\n",
    "    \"\"\"\n",
    "\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n - 1):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\n",
    "model = HfApiModel(model_id=model_id, token=hf_key)\n",
    "\n",
    "# Configurar el agente con la tool de Fibonacci\n",
    "agent = CodeAgent(tools=[fibonacci], model=model, add_base_tools=True)\n",
    "\n",
    "# Ejecutar la consulta al agente\n",
    "response = agent.run(\"What is the 118th Fibonacci number?\")\n",
    "\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de definir la tool pero usando una class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, HfApiModel\n",
    "from smolagents.tools import Tool\n",
    "import os\n",
    "\n",
    "# Definir la clase Fibonacci heredando de Tool\n",
    "class FibonacciTool(Tool):\n",
    "    name = \"fibonacci\"  # Agregamos el atributo name\n",
    "    description = \"Calculates the nth Fibonacci number.\"\n",
    "    inputs = {\n",
    "        \"n\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The position in the Fibonacci sequence to calculate\"\n",
    "        }\n",
    "    }\n",
    "    output_type = \"integer\"  # Añadimos el tipo de salida\n",
    "     \n",
    "    def forward(self, n: int) -> int:\n",
    "        \"\"\"Calcula el enésimo número de Fibonacci.\"\"\"\n",
    "        a, b = 0, 1\n",
    "        for _ in range(n - 1):\n",
    "            a, b = b, a + b\n",
    "        return a\n",
    "\n",
    "# Crear una instancia de la herramienta\n",
    "fibonacci_tool = FibonacciTool()\n",
    "\n",
    "\n",
    "# Usar HfApiModel con una clave de Hugging Face\n",
    "# hf_key = os.getenv(\"HF_TOKEN\")  # Asegúrate de definir esta variable en tu entorno\n",
    "# model_id = \"meta-llama/Llama-3.3-70B-Instruct\"  # Puedes cambiarlo por otro modelo disponible\n",
    "\n",
    "model = HfApiModel(model_id=model_id, token=hf_key)\n",
    "\n",
    "# Configurar el agente con la tool de Fibonacci\n",
    "agent = CodeAgent(tools=[fibonacci_tool], model=model, add_base_tools=True)\n",
    "\n",
    "# Ejecutar la consulta al agente\n",
    "response = agent.run(\"What is the 118th Fibonacci number?\")\n",
    "\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting an agent run\n",
    "\n",
    "Here are a few useful attributes to inspect what happened after a run:\n",
    "\n",
    "agent.logs\n",
    "Stores the fine-grained logs of the agent. At every step of the agent’s run, everything gets stored in a dictionary that then is appended to agent.logs.\n",
    "\n",
    "Running agent.write_memory_to_messages() writes the agent’s memory as list of chat messages for the Model to view. This method goes over each step of the log and only stores what it’s interested in as a message: for instance, it will save the system prompt and task in separate messages, then for each step it will store the LLM output as a message, and the tool call output as another message. Use this if you want a higher-level view of what has happened - but not every log will be transcripted by this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Buscar en internet conDuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import DuckDuckGoSearchTool\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "print(search_tool(\"Who's the current president of Russia?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
